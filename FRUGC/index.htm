<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>FR-UGC</title>
 <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="ugc384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
       <link rel="stylesheet" href="../css/style.css">
</head>

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1><center>Full-reference Video Quality Assessment for User Generated Content Transcoding</center></h1>
                                <div class="container-sm">
                                    <div class="row justify-content-md-center">
									
									<div class="col-sm-auto">
                                            <p>Zihao Qi<sup>1</sup></p>
                                        </div>

									<div class="col-sm-auto">
                                            <p><a href='https://chenfeng-bristol.github.io/'>Chen Feng</a><sup>1</sup></p>
                                        </div>

									<div class="col-sm-auto">
                                            <p><a href='https://danier97.github.io/'>Duolikun Danier</a><sup>1</sup></p>
                                        </div>

									<div class="col-sm-auto">
                                            <p><a href='https://seis.bristol.ac.uk/~eexfz/index.htm'>Fan Zhang</a><sup>1</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Shan Liu<sup>2</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Xiaozhong Xu<sup>2</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p><a href='https://david-bull.github.io/'>David Bull</a><sup>1</sup></p>
                                        </div>
									
                                    </div>
									<center><div class="col-sm-auto">
                                            <p><sup>1</sup>University of Bristol</p>
                                        </div>
										<div class="col-sm-auto">
                                            <p><sup>2</sup>Tencent (US)</p>
                                        </div></center>
                                </div>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.png" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VILogo.jpg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
			
            <div class="container-md">
				<h2>Abstract</h2>
				<p>Unlike video coding for professional content, the delivery pipeline of User Generated Content (UGC) involves transcoding where unpristine reference content needs to be compressed repeatedly. In this work, we observe that existing full-/no-reference quality metrics fail to accurately predict the perceptual quality difference between transcoded UGC content and the corresponding unpristine references. Therefore, they are unsuited for guiding the rate-distortion optimisation process in the transcoding process. </p>
				<center><img src="./UGCpipeline.jpg" width="60%" alt=""> </center>
				<p>In this context, we propose a bespoke full-reference deep video quality metric for UGC transcoding. The proposed method features a transcoding-specific weakly supervised training strategy employing a quality ranking-based Siamese structure. The proposed method is evaluated on the YouTube-UGC VP9 subset and the LIVE-Wild database, demonstrating state-of-the-art performance compared to existing VQA methods. </p>
            </div>
            <hr />
            
            <div class="container-md">
                <h2>Generation of FR-UGC training data</h2>
				<p>(A) Training datasets is generated in two steps to simulate the UGC delivery pipeline. First pristine source sequences are compressed by H.264 to obtain distorted reference. Then, the distorted reference is further compressed by 4 popular codecs into 12 transcoded variants. This results in 9,288 transcoded sequences.</p>
				<p>(B) Proxy quality metric (VMAF) is used to generate reliable quality labels for the training content. We always use pristine content as references in the VMAF calculations, the accuracy of the quality prediction has been maintained. </p>
                <center><img src="./generateTrain.jpg" width="100%" alt=""> </center>
            </div>
			
			<hr />
            <div class="container-md">
                <h2>Model and Loss function</h2>
				<p>(A) The overall picture of the inference workflow. </p>
				<p>(B) The illustration of the proposed training strategy.</p>
                <center><img src="./model.jpg" width="100%" alt=""> </center>
            </div>
			
			<hr />
			
			<div class="container-md">
                <h2 id="downloads">Useful Links <b style="color: red">[not yet]</b></h2>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] code repos</p>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] trainset</p>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] quality labels</p>
Please read the README file before using the data.

            </div>
			<hr />
			
            <div class="container-md">
                <h2>Citation</h2>
				<pre class="citation">
@inproceedings{qi2024full,
  title={Full-reference video quality assessment for user generated content transcoding},
  author={Qi, Zihao and Feng, Chen and Danier, Duolikun and Zhang, Fan and Xu, Xiaozhong and Liu, Shan and Bull, David},
  booktitle={2024 Picture Coding Symposium (PCS)},
  pages={1--5},
  year={2024},
  organization={IEEE}
}<A HREF="https://ieeexplore.ieee.org/abstract/document/not-yet-available">[paper]</a></pre>

            </div>
			<hr />
            

        
		</div>
    </div>
</body>

</html>
