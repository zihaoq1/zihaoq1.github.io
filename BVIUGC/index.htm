<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>BVI-UGC</title>
 <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
       <link rel="stylesheet" href="../css/style.css">
</head>

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1><center>BVI-UGC: A Training Database for UGC Video Quality Assessment and Video Coding</center></h1>
                                <div class="container-sm">
                                    <div class="row justify-content-md-center">
									
									<div class="col-sm-auto">
                                            <p>Zihao Qi</p>
                                        </div>
										
									<div class="col-sm-auto">
                                            <p><a href='https://seis.bristol.ac.uk/~eexfz/index.htm'>Fan Zhang</a></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Shan Liu</p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Xiaozhong Xu</p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p><a href='https://david-bull.github.io/'>David Bull</a></p>
                                        </div>
									
                                    </div>
									<center><p>University of Bristol</p></center>
                                </div>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.png" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VILogo.jpg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
			<!--
            <div class="container-md">
                <h2>About</h2>
				<p>As UGC videos are playing an increasingly important role in video traffic, they differ from conventional videos in many aspects: first, access to pristine source sequence is usually not available; second, sequences are usually shot by unprofessional individuals with low-standard inconsistent equipments; third, sequences could have be heavily edited, containing artificial content such as filtering-effect, animation, and text; lastly, there are novel and unique content emerging in UGC such as YouTuber and virtual YouTuber livestream, which is new to conventional video content. It is natural that traditional metrics designed and trained for conventional database do not fit well with UGC. Moreover, current best performing algorithms are generally built on the assumption that full access to pristine original videos is available, which no longer holds for UGC videos. </p>
				<p>BVI-UGC is a high definition video database designed for UGC video quality assessment and video coding, which contains 145 reference video sequences and massive amount of distorted sequences from multiple popular codecs (AVC, HEVC, AV1, etc). BVI-UGC contains high-quality source videos with diverse and representative textures, aimming at enhancing Deep Learning-based methods for UGC video quality assessment and video coding. Considering the fact that many UGC videos are in portrait view, it contains both landscape videos and portrait videos (the ratio is roughly 1:1). </p>
            </div>
            <hr />
            <div class="container-md">
                <h2 id="downloads">Useful Links [not yet available]</h2>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] instructions and related file</p>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] all videos</p>
<p>[<a href="https://vilab.blogs.bristol.ac.uk/files/currently-not-available"><strong>DOWNLOAD</strong></a>] all subjective data.</p>
Please read the README file before using the data.

            </div>
			
			<hr />
            <div class="container-md">
                <h2>Sample frames from BVI-UGC</h2>
				<p>To ensure that BVI-UGC well reflects the statistics of videos on UGC platforms (such TikTok, YouTube), the videos are collected according to 14 categories that are popular on these platforms.</p>
				<p>To be noted, the sample frames are randomly picked. Every category contains both landscape videos and portrait videos (the ratio is roughly 1:1).</p>
                <center><img src="./Samples.png" width="100%" alt=""> </center>
            </div>
			
			<hr />
            <div class="container-md">
                <h2>Citation</h2>
				<pre class="citation">
@article{zihao2022bvi,
  title={BVI-UGC: Not yet available},
  author={Name1, Name2},
  journal={Journal},
  volume={111},
  number={222},
  pages={333},
  year={2022},
  publisher={IEEE}
}<A HREF="https://ieeexplore.ieee.org/abstract/document/not-yet-available">[paper]</a></pre>

            </div>
			<hr />
            

        -->
		</div>
    </div>
</body>

</html>
