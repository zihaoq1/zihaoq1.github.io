<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">

    <title>BVI-UGC</title>
 <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
       <link rel="stylesheet" href="../css/style.css">
</head>

<body id="page-top">
    <div class="page-container">
        <div class="inner">
            <div class="container">
                <div class="row">
                    <div class="row vertical-align">
  
                        <div class="col-md-10">
                            <div class="title">
                                <h1><center>BVI-UGC: A Video Quality Database for User-Generated Content Transcoding</center></h1>
                                <div class="container-sm">
                                    <div class="row justify-content-md-center">
									
									<div class="col-sm-auto">
                                            <p>Zihao Qi<sup>1</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p><a href='https://chenfeng-bristol.github.io/'>Chen Feng</a><sup>1</sup></p>
                                        </div>
										
									<div class="col-sm-auto">
                                            <p><a href='https://seis.bristol.ac.uk/~eexfz/index.htm'>Fan Zhang</a><sup>1</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Shan Liu<sup>2</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p>Xiaozhong Xu<sup>2</sup></p>
                                        </div>
									
									<div class="col-sm-auto">
                                            <p><a href='https://david-bull.github.io/'>David Bull</a><sup>1</sup></p>
                                        </div>
									
                                    </div>
									<center><div class="col-sm-auto">
                                            <p><sup>1</sup>University of Bristol</p>
                                        </div>
										<div class="col-sm-auto">
                                            <p><sup>2</sup>Tencent (US)</p>
                                        </div></center>
                                </div>
                            </div>
                        </div>
			<div class="col-md-2">
			    <p><a href='https://www.bristol.ac.uk'><img src="../uob-logo.svg" width="100%" height="20%" alt=""></a></p>
			    <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="../bvilogo.png" width="100%" height="20%" alt=""></a></p>
			     <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="../VILogo.jpg" width="100%" height="20%" alt=""></a></p>
			    
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-md">
                <h2>About</h2>
				<p>In recent years, user-generated content (UGC) has become one of the major video types consumed  via streaming networks. Numerous research contributions have focused on assessing its visual quality through subjective tests and objective modeling. In most cases, objective assessments are based on a no-reference scenario, where the corresponding reference content is assumed not to be available. However, full-reference video quality assessment is also important for UGC in the delivery pipeline, particularly associated with the video transcoding process. </p>
				<p>In this context, we present a new UGC video quality database, BVI-UGC, for user-generated content transcoding, which contains 60 (non-pristine) reference videos and 1,080 test sequences. In this work, we simulated the creation of non-pristine reference sequences (with a wide range of compression distortions), typical of content uploaded to UGC platforms for transcoding. A comprehensive crowdsourced subjective study was then conducted involving more than 3,500 human participants. Based on this collected subjective data, we benchmarked the performance of 10 full-reference and 11 no-reference quality metrics. Our results demonstrate the poor performance (SROCC values are lower than 0.6) of these metrics in predicting the perceptual quality of UGC in two different scenarios (with or without a reference). </p>
            </div>
            <hr />
            <div class="container-md">
                <h2 id="downloads">Useful Links </h2>
<p>[<a href="https://forms.office.com/Pages/ResponsePage.aspx?id=MH_ksn3NTkql2rGM8aQVGzWqVNJtv7tNq2EVc88EH7BUNzJLVDhEWUtSREpONlkzQzZONDUxVDA4Uy4u"><strong>LINK</strong></a>] sign form to get access to the data</p>
Please read the <a href="https://zihaoq1.github.io/BVI-UGC/ATTRIBUTION.txt"><strong>ATTRIBUTION</strong></a> and agree to the <a href="https://zihaoq1.github.io/BVI-UGC/LICENSE.txt"><strong>LICENSE</strong></a> before using the data.

            </div>
			
			<hr />
            <div class="container-md">
                <h2>Sample frames from BVI-UGC</h2>
				<p>In order to develop a database with diverse and representative source content, we defined 15 typical UGC categories following the scope of existing UGC databases and the genres on popular UGC platforms (e.g. YouTube, Tiktok, Flickr etc.).</p>
				<p>Example frames in selected videos from 15 UGC catogories defined in this database. Every category contains both landscape and portrait videos (the ratio is approximately 2:1).</p>
                <center><img src="./Samples.jpg" width="100%" alt=""> </center>
            </div>
			
			<hr />
            <div class="container-md">
                <h2>Citation</h2>
				<pre class="citation">
@article{qi2024bvi,
  title={{BVI-UGC}: A Video Quality Database for User-Generated Content Transcoding},
  author={Qi, Zihao and Feng, Chen and Zhang, Fan and Xu, Xiaozhong and Liu, Shan and Bull, David},
  journal={arXiv preprint arXiv:2408.07171},
  year={2024}
}<A HREF="https://arxiv.org/abs/2408.07171">[paper]</a></pre>

            </div>
			<hr />
            

		</div>
    </div>
</body>

</html>
